{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing os, shutil and glob for copying concrete images from raw folder to the new structure which is \n",
    "#required for ImageDataGenerator.flow_from_directory\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store references of cracked and uncracked images of concrete\n",
    "data = {}\n",
    "data['crack'] = []\n",
    "data['uncrack'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking cracked image's paths from respective folder and storing them in our dictionary\n",
    "src = 'concrete_dataset/ConcreteCrackImagesforClassification/Positive'\n",
    "for jpgImage in glob.iglob(os.path.join(src, '*jpg')):\n",
    "    data['crack'].append(jpgImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "#we can see the number of cracked images are 20000\n",
    "print(len(data['crack']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking uncracked image's paths from respective folder and storing them in our dictionary\n",
    "src = 'concrete_dataset/ConcreteCrackImagesforClassification/Negative'\n",
    "for jpgImage in glob.iglob(os.path.join(src, '*jpg')):\n",
    "    data['uncrack'].append(jpgImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "#we can see the number of uncracked images are also 20000\n",
    "print(len(data['uncrack']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating directory structures which is required for our model to train.\n",
    "os.mkdir('master_data_concrete')\n",
    "os.mkdir('master_data_concrete/training')\n",
    "os.mkdir('master_data_concrete/testing')\n",
    "\n",
    "os.mkdir('master_data_concrete/training/crack')\n",
    "os.mkdir('master_data_concrete/training/uncrack')\n",
    "os.mkdir('master_data_concrete/testing/crack')\n",
    "os.mkdir('master_data_concrete/testing/uncrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets copy 75% of cracked and uncracked images into training data folder and rest 25% to testing data folder\n",
    "split_size = 0.75\n",
    "for class_type, imagesList in data.items():\n",
    "    train_size = int(split_size*(len(imagesList)))\n",
    "    train_images_list = imagesList[:train_size]\n",
    "    test_images_list = imagesList[train_size:]\n",
    "    \n",
    "    base_dest = 'master_data_concrete'\n",
    "    #copy training  images of crack type\n",
    "    for image in train_images_list:\n",
    "        dest = os.path.join(base_dest, 'training', class_type)\n",
    "        shutil.copy(image, dest)\n",
    "\n",
    "    #copy testing images of crack type\n",
    "    for image in test_images_list:\n",
    "        dest = os.path.join(base_dest, 'testing', class_type)\n",
    "        shutil.copy(image, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(227, 227, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amitv\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1)) # this our output layer (since this is binary classification of cracked or uncracked, we use only one unit in output layer).\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "#here alng with rescaling, we are also changing the orientation of the image in only training dataset, \n",
    "#this is we are doing so that our model never sees the same image, and this will help in fighting overfitting.\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'master_data_concrete/training', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(227, 227),  # all images will be resized to 227*227\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(227, 227),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=2, min_delta=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amitv\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 273s 146ms/step - loss: 0.4839 - accuracy: 0.9369 - val_loss: 0.0049 - val_accuracy: 0.9888\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 263s 140ms/step - loss: 0.1687 - accuracy: 0.9669 - val_loss: 0.0107 - val_accuracy: 0.9787\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 259s 138ms/step - loss: 0.1781 - accuracy: 0.9723 - val_loss: 5.9048e-04 - val_accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "#         steps_per_epoch=30000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "#         validation_steps=10000 // batch_size,\n",
    "        callbacks=[es])\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11070291697978973, 0.9890000224113464]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
